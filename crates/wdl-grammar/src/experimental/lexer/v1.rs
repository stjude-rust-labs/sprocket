//! WDL (v1) tokens.

use std::fmt;

use logos::Logos;

use super::Error;

/// Represents a token in a single quoted string (e.g. `'hello'`).
#[derive(Logos, Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
#[repr(u8)]
#[logos(error = Error)]
pub enum SQStringToken {
    /// A start of a placeholder.
    ///
    /// When encountered, [morph][super::Lexer::morph] the lexer to use [Token].
    #[token("┹［麸脲瞑┹徐徙彖镬溴蛴翎螋澡篝狎镦犷弩汜疱箦聃孱沐澡轶麸脲轶泔铙殇弪邃疳螋镦翳扉翦蜥翦舢物翦翳狒弩汜疱箦聃孱沐狎铒鲠扉溽翦怡翳戾弪［蝈珏颌苘┹朋汜疱箴犷镦扉翦蜥翦舢［蝈珏颌坜苘л┹藻衄滹祆狎箝珙翳狒轶疳螋镦扉翦蜥翦舢［麸脲瞑あ┹娘祆狎娱珙糸熹翳狒轶疳螋镦翳扉翦蜥翦舢［麸脲瞑┹蚤熹瀣令孱溟铉箝铉戾聃雉瀹阻孱孱泔躅翦蝈洮垌矧痂蒇篚疱蚝禾屮弪汉盹蝠栎翳戾弪麸躞墼镫孱莓［麸脲瞑Б┹蓬洮义痱弩孱趔麸脲轭滹踱戾聃雉邃篝蜷铉ㄥ绠啖桢祆铫喋［溴蜷鲥ㄌ镧矬腻怩绗渺镱瀣蔑瘗嗅螋獒炫瘳篷嗅螋獒煜蜾向洮柔箬┹［蝈痱醺┹［祜顼蟥弪蝻膨蝻颟瘐孱蹴难郁蜷铉燥脲篝狎镦痨徙彖镬溴虍阻孱孱泔躅翦蝈洮垌矧痂蒇篚疱蚝禾屮弪汉盹蝠栎翳戾弪麸躞墼镫孱莓［麸脲瞑┹［麸脲瞑┹徐徙彖镬溴蛴翎螋澡篝狎镦犷弩汜疱箦聃孱沐澡轶麸脲轶泔铙殇弪邃疳螋镦翳扉翦蜥翦舢物翦翳狒弩汜疱箦聃孱沐狎铒鲠扉溽翦怡翳戾弪［蝈珏颌苘┹朋汜疱箴犷镦扉翦蜥翦镦翳篝蜷铉［蝈珏颍③捃埭⑤）藻衄滹祆狎箝珙翳狒轶疳螋镦扉翦蜥翦舢［麸脲瞑あ┹娘祆狎娱珙糸熹翳狒轶疳螋镦翳扉翦蜥翦舢［麸脲瞑┹蚤熹瀣令孱溟铉滹踱戾聃雉瀹阻孱孱泔躅翦蝈洮垌矧痂蒇篚疱蚝禾屮弪汉盹蝠栎翳戾弪麸躞墼镫孱莓［麸脲瞑④┹蓬洮义痱弩孱趔麸脲轭桢蝈滹泔眄犷ㄥ绠嗉技桢祆揪距┊［溴蜷鲥ㄌ镧矬腻怩绗渺镱瀣蔑瘗嗅螋獒炫瘳篷嗅螋獒煜蜾向洮柔箬┹［蝈痱醺┹［祜顼蟥弪蝻膨蝻颟瘐孱蹴儒蝈滹忝镯磲钿燥脲篝狎镦痨徙彖镬溴虍阻孱孱泔躅翦蝈洮垌矧痂蒇篚疱蚝禾屮弪汉盹蝠栎翳戾弪麸躞墼镫孱莓［麸脲瞑┹徐徙彖镬溴蛴翎螋澡篝狎镦犷弩汜疱箦聃孱沐澡轶麸脲轶泔铙殇弪邃疳螋镦翳扉翦蜥翦舢物翦翳狒弩汜疱箦聃孱沐狎铒鲠扉溽翦怡翳戾弪［蝈珏颌苘┹朋汜疱箴犷镦扉翦蜥翦舢［蝈珏颌坜苘据┹藻衄糸熹翳狒轶疳螋镦翳扉翦蜥翦舢［麸脲瞑┹蚤熹瀣令孱溟铉犷珈怛徙脲舢阻孱翳蝈镦翳弩麸脲铙狎箦聃孱糸犰禊孱泔躅翦蝈洮垌矧痂蒇篚疱蚝禾屮弪汉盹蝠栎翳戾弪麸躞墼镫孱莓萧桢蝼轶瀣泔铙殇弪翳麸脲麸忮疳螋镦翳扉翦蜥翦舢［麸脲瞑⒕┹蓬洮义痱弩孱趔麸脲轭犷镬溴颦篝戾怛徙泔眄犷洚［溴蜷鲥ㄌ镧矬腻怩绗渺镱瀣蔑瘗嗅螋獒炫瘳篷嗅螋獒煜蜾向洮柔箬┹［蝈痱醺┹［祜顼蟥弪蝻膨蝻颟瘐孱蹴买徙迕镯磲钿燥脲篝狎镦痨徙彖镬溴虍阻孱孱泔躅翦蝈洮垌矧痂蒇篚疱蚝禾屮弪汉盹蝠栎翳戾弪麸躞墼镫孱莓［麸脲瞑┹［麸脲瞑┹徐徙彖镬溴蛴翎螋澡篝狎镦犷弩汜疱箦聃孱沐澡轶麸脲轶泔铙殇弪邃疳螋镦翳扉翦蜥翦舢物翦翳狒弩汜疱箦聃孱沐狎铒鲠扉溽翦怡翳戾弪［蝈珏颌苘┹朋汜疱箴犷镦扉翦蜥翦舢［蝈珏颌坜苘]+")]
    Text,

    /// A dollar sign that is part of literal text.
    #[token("$")]
    DollarSign,

    /// A tilde that is part of the literal text.
    #[token("")]
    Tilde,

    /// An ending close brace.
    ///
    /// When encountered, [morph][super::Lexer::morph] the lexer to use [Token].
    #[token("}")]
    End,
}

/// Represents a WDL (v1) token.
///
/// As WDL supports string interpolation, sub-lexers are used when certain
/// tokens are encountered:
///
/// | Token                                                                    | Sub-lexer token       |
/// |--------------------------------------------------------------------------|-----------------------|
/// | [SQStringStart][Token::SQStringStart]                                    | [SQStringToken]       |
/// | [DQStringStart][Token::DQStringStart]                                    | [DQStringToken]       |
/// | [HeredocCommandStart][Token::HeredocCommandStart]                        | [HeredocCommandToken] |
/// | [CommandKeyword][Token::CommandKeyword] > [OpenBrace][Token::OpenBrace] | [BraceCommandToken]   |
///
/// After the start token is encountered, the [morph][super::Lexer::morph]
/// method is used to morph the current lexer into a sub-lexer.
///
/// When the sub-lexer token's `End` variant is encountered,
/// [morph][super::Lexer::morph] is called again to morph the sub-lexer back to
/// the WDL lexer using the [Token] type.
///
/// An unterminated string or heredoc can be determined by the lexer iterator
/// terminating before the sub-lexer token's `End` variant is encountered.
#[derive(Logos, Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
#[repr(u8)]
#[logos(error = Error)]
#[logos(subpattern exp = r"[eE][+-]?[0-9]+")]
#[logos(subpattern id = r"[a-zA-Z][a-zA-Z0-9_]*")]
pub enum Token {
    /// Contiguous whitespace.
    #[regex(r"[ \t\r\n]+")]
    Whitespace,

    /// A comment.
    #[regex(r"#[^\n]*")]
    Comment,

    /// A literal float.
    #[regex(r"[0-9]+(?&exp)")]
    #[regex(r"[0-9]+\.[0-9]*(?&exp)?", priority = 5)]
    #[regex(r"[0-9]*\.[0-9]+(?&exp)?")]
    Float,

    /// A literal integer.
    #[token("0")]
    #[regex(r"[1-9][0-9]+")]
    #[regex(r"0[0-7]+")]
    #[regex(r"0[xX][0-9a-fA-F]+")]
    Integer,

    /// An identifier.
    #[regex(r"(?&id)")]
    Ident,

    /// A qualified name.
    #[regex(r"(?&id)(\.(?&id))+")]
    QualifiedName,

    /// A start of a single-quoted string.
    ///
    /// When encountered, [morph][super::Lexer::morph] the lexer to use
    /// [SQStringToken].
    #[token("'")]
    SQStringStart,

    /// A start of a double-quoted string.
    ///
    /// When encountered, [morph][super::Lexer::morph] the lexer to use
    /// [DQStringToken].
    #[token("\"")]
    DQStringStart,

    /// A start of a heredoc command.
    ///
    /// When encountered, [morph][super::Lexer::morph] the lexer to use
    /// [HeredocCommandToken].
    #[token("<<<")]
    HeredocCommandStart,

    /// The `Array` type keyword.
    #[token("Array")]
    ArrayTypeKeyword,
    /// The `Boolean` type keyword.
    #[token("Boolean")]
    BooleanTypeKeyword,
    /// The `File` type keyword.
    #[token("File")]
    FileTypeKeyword,
    /// The `Float` type keyword.
    #[token("Float")]
    FloatTypeKeyword,
    /// The `Int` type keyword.
    #[token("Int")]
    IntTypeKeyword,
    /// The `Map` type keyword.
    #[token("Map")]
    MapTypeKeyword,
    /// The `None` type keyword.
    #[token("None")]
    NoneTypeKeyword,
    /// The `Object` type keyword.
    #[token("Object")]
    ObjectTypeKeyword,
    /// The `Pair` type keyword.
    #[token("Pair")]
    PairTypeKeyword,
    /// The `String` type keyword.
    #[token("String")]
    StringTypeKeyword,
    /// The `alias` keyword.
    #[token("alias")]
    AliasKeyword,
    /// The `as` keyword.
    #[token("as")]
    AsKeyword,
    /// The `call` keyword.
    #[token("call")]
    CallKeyword,
    /// The `command` keyword.
    #[token("command")]
    CommandKeyword,
    /// The `else` keyword.
    #[token("else")]
    ElseKeyword,
    /// The `false` keyword.
    #[token("false")]
    FalseKeyword,
    /// The `if` keyword.
    #[token("if")]
    IfKeyword,
    /// The `in` keyword.
    #[token("in")]
    InKeyword,
    /// The `import` keyword.
    #[token("import")]
    ImportKeyword,
    /// The `input` keyword.
    #[token("input")]
    InputKeyword,
    /// The `meta` keyword.
    #[token("meta")]
    MetaKeyword,
    /// The `null` keyword.
    #[token("null")]
    NullKeyword,
    /// The `object` keyword.
    #[token("object")]
    ObjectKeyword,
    /// The `output` keyword.
    #[token("output")]
    OutputKeyword,
    /// The `parameter_meta` keyword.
    #[token("parameter_meta")]
    ParameterMetaKeyword,
    /// The `runtime` keyword.
    #[token("runtime")]
    RuntimeKeyword,
    /// The `scatter` keyword.
    #[token("scatter")]
    ScatterKeyword,
    /// The `struct` keyword.
    #[token("struct")]
    StructKeyword,
    /// The `task` keyword.
    #[token("task")]
    TaskKeyword,
    /// The `then` keyword.
    #[token("then")]
    ThenKeyword,
    /// The `true` keyword.
    #[token("true")]
    TrueKeyword,
    /// The `version` keyword.
    #[token("version")]
    VersionKeyword,
    /// The `workflow` keyword.
    #[token("workflow")]
    WorkflowKeyword,

    /// The reserved `Directory` type keyword.
    #[token("Directory")]
    ReservedDirectoryTypeKeyword,
    /// The reserved `hints` keyword.
    #[token("hints")]
    ReservedHintsKeyword,
    /// The reserved `requirements` keyword.
    #[token("requirements")]
    ReservedRequirementsKeyword,

    /// The `{` symbol.
    #[token("{")]
    OpenBrace,
    /// The `}` symbol.
    #[token("}")]
    CloseBrace,
    /// The `[` symbol.
    #[token("[")]
    OpenBracket,
    /// The `]` symbol.
    #[token("]")]
    CloseBracket,
    /// The `=` symbol.
    #[token("=")]
    Assignment,
    /// The `:` symbol.
    #[token(":")]
    Colon,
    /// The `,` symbol.
    #[token(",")]
    Comma,
    /// The `(` symbol.
    #[token("(")]
    OpenParen,
    /// The `)` symbol.
    #[token(")")]
    CloseParen,
    /// The `?` symbol.
    #[token("?")]
    QuestionMark,
    /// The `!` symbol.
    #[token("!")]
    Exclamation,
    /// The `+` symbol.
    #[token("+")]
    Plus,
    /// The `-` symbol.
    #[token("-")]
    Minus,
    /// The `||` symbol.
    #[token("||")]
    LogicalOr,
    /// The `&&` symbol.
    #[token("&&")]
    LogicalAnd,
    /// The `*` symbol.
    #[token("*")]
    Asterisk,
    /// The `/` symbol.
    #[token("/")]
    Slash,
    /// The `%` symbol.
    #[token("%")]
    Percent,
    /// The `==` symbol.
    #[token("==")]
    Equal,
    /// The `!=` symbol.
    #[token("!=")]
    NotEqual,
    /// The `<=` symbol.
    #[token("<=")]
    LessEqual,
    /// The `>=` symbol.
    #[token(">=")]
    GreaterEqual,
    /// The `<` symbol.
    #[token("<")]
    Less,
    /// The `>` symbol.
    #[token(">")]
    Greater,
    /// The `.` symbol.
    #[token(".")]
    Dot,

    // WARNING: this must always be the last variant.
    /// The exclusive maximum token value.
    MAX,
}

// There can only be 128 tokens in a TokenSet.
const _: () = assert!(Token::MAX as u8 <= 128);

impl fmt::Display for Token {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Self::Whitespace => write!(f, "whitespace"),
            Self::Comment => write!(f, "comment"),
            Self::Float => write!(f, "float"),
            Self::Integer => write!(f, "integer"),
            Self::Ident => write!(f, "identifier"),
            Self::QualifiedName => write!(f, "qualified name"),
            Self::SQStringStart => write!(f, "`'`"),
            Self::DQStringStart => write!(f, "`\"`"),
            Self::HeredocCommandStart => write!(f, "`<<<`"),
            Self::ArrayTypeKeyword => write!(f, "`Array` keyword"),
            Self::BooleanTypeKeyword => write!(f, "`Boolean` keyword"),
            Self::FileTypeKeyword => write!(f, "`File` keyword"),
            Self::FloatTypeKeyword => write!(f, "`Float` keyword"),
            Self::IntTypeKeyword => write!(f, "`Int` keyword"),
            Self::MapTypeKeyword => write!(f, "`Map` keyword"),
            Self::NoneTypeKeyword => write!(f, "`None` keyword"),
            Self::ObjectTypeKeyword => write!(f, "`Object` keyword"),
            Self::PairTypeKeyword => write!(f, "`Pair` keyword"),
            Self::StringTypeKeyword => write!(f, "`String` keyword"),
            Self::AliasKeyword => write!(f, "`alias` keyword"),
            Self::AsKeyword => write!(f, "`as` keyword"),
            Self::CallKeyword => write!(f, "`call` keyword"),
            Self::CommandKeyword => write!(f, "`command` keyword"),
            Self::ElseKeyword => write!(f, "`else` keyword"),
            Self::FalseKeyword => write!(f, "`false` keyword"),
            Self::IfKeyword => write!(f, "`if` keyword"),
            Self::InKeyword => write!(f, "`int` keyword"),
            Self::ImportKeyword => write!(f, "`import` keyword"),
            Self::InputKeyword => write!(f, "`input` keyword"),
            Self::MetaKeyword => write!(f, "`meta` keyword"),
            Self::NullKeyword => write!(f, "`null` keyword"),
            Self::ObjectKeyword => write!(f, "`object` keyword"),
            Self::OutputKeyword => write!(f, "`output` keyword"),
            Self::ParameterMetaKeyword => write!(f, "`parameter_meta` keyword"),
            Self::RuntimeKeyword => write!(f, "`runtime` keyword"),
            Self::ScatterKeyword => write!(f, "`scatter` keyword"),
            Self::StructKeyword => write!(f, "`struct` keyword"),
            Self::TaskKeyword => write!(f, "`task` keyword"),
            Self::ThenKeyword => write!(f, "`then` keyword"),
            Self::TrueKeyword => write!(f, "`true` keyword"),
            Self::VersionKeyword => write!(f, "`version` keyword"),
            Self::WorkflowKeyword => write!(f, "`workflow` keyword"),
            Self::ReservedDirectoryTypeKeyword => write!(f, "reserved `Directory` keyword"),
            Self::ReservedHintsKeyword => write!(f, "reserved `hints` keyword"),
            Self::ReservedRequirementsKeyword => write!(f, "reserved `requirements` keyword"),
            Self::OpenBrace => write!(f, "`{{`"),
            Self::CloseBrace => write!(f, "`}}`"),
            Self::OpenBracket => write!(f, "`[`"),
            Self::CloseBracket => write!(f, "`]`"),
            Self::Assignment => write!(f, "`=`"),
            Self::Colon => write!(f, "`:`"),
            Self::Comma => write!(f, "`,`"),
            Self::OpenParen => write!(f, "`(`"),
            Self::CloseParen => write!(f, "`)`"),
            Self::QuestionMark => write!(f, "`?`"),
            Self::Exclamation => write!(f, "`!`"),
            Self::Plus => write!(f, "`+`"),
            Self::Minus => write!(f, "`-`"),
            Self::LogicalOr => write!(f, "`||`"),
            Self::LogicalAnd => write!(f, "`&&`"),
            Self::Asterisk => write!(f, "`*`"),
            Self::Slash => write!(f, "`/`"),
            Self::Percent => write!(f, "`%`"),
            Self::Equal => write!(f, "`==`"),
            Self::NotEqual => write!(f, "`!=`"),
            Self::LessEqual => write!(f, "`<=`"),
            Self::GreaterEqual => write!(f, "`>=`"),
            Self::Less => write!(f, "`<`"),
            Self::Greater => write!(f, "`>`"),
            Self::Dot => write!(f, "`.`"),
            Self::MAX => unreachable!(),
        }
    }
}

#[cfg(test)]
mod test {
    use pretty_assertions::assert_eq;

    use super::*;
    use crate::experimental::lexer::test::map;
    use crate::experimental::lexer::Lexer;

    #[test]
    pub fn whitespace() {
        let lexer = Lexer::<Token>::new(" \t\r\n");
        let tokens: Vec<_> = lexer.map(map).collect();
        assert_eq!(
            tokens,
            &[(Ok(Token::Whitespace), 0..4)],
            "produced tokens did not match the expected set"
        );
    }

    #[test]
    fn comments() {
        use Token::*;
        let lexer = Lexer::<Token>::new(
            r#"
## first comment
# second comment
#### third comment"#,
        );
        let tokens: Vec<_> = lexer.map(map).collect();
        assert_eq!(
            tokens,
            &[
                (Ok(Whitespace), 0..1),
                (Ok(Comment), 1..17),
                (Ok(Whitespace), 17..18),
                (Ok(Comment), 18..34),
                (Ok(Whitespace), 34..35),
                (Ok(Comment), 35..53)
            ],
            "produced tokens did not match the expected set"
        );
    }

    #[test]
    fn float() {
        use Token::*;
        let lexer = Lexer::<Token>::new(
            r#"
0.
0.0
.0
.123
0.123
123.0
123.123
123e123
123E123
123e+123
123E+123
123e-123
123E-123
123.e123
123.E123
123.e+123
123.E+123
123.e-123
123.E-123
.123e+123
.123E+123
.123e-123
.123E-123
0.123e+123
0.123E+123
0.123e-123
0.123E-123
123.123e123
123.123E123
123.123e+123
123.123E+123
123.123e-123
123.123E-123"#,
        );

        let tokens: Vec<_> = lexer.map(map).collect();
        assert_eq!(
            tokens,
            &[
                (Ok(Whitespace), 0..1),
                (Ok(Float), 1..3),
                (Ok(Whitespace), 3..4),
                (Ok(Float), 4..7),
                (Ok(Whitespace), 7..8),
                (Ok(Float), 8..10),
                (Ok(Whitespace), 10..11),
                (Ok(Float), 11..15),
                (Ok(Whitespace), 15..16),
                (Ok(Float), 16..21),
                (Ok(Whitespace), 21..22),
                (Ok(Float), 22..27),
                (Ok(Whitespace), 27..28),
                (Ok(Float), 28..35),
                (Ok(Whitespace), 35..36),
                (Ok(Float), 36..43),
                (Ok(Whitespace), 43..44),
                (Ok(Float), 44..51),
                (Ok(Whitespace), 51..52),
                (Ok(Float), 52..60),
                (Ok(Whitespace), 60..61),
                (Ok(Float), 61..69),
                (Ok(Whitespace), 69..70),
                (Ok(Float), 70..78),
                (Ok(Whitespace), 78..79),
                (Ok(Float), 79..87),
                (Ok(Whitespace), 87..88),
                (Ok(Float), 88..96),
                (Ok(Whitespace), 96..97),
                (Ok(Float), 97..105),
                (Ok(Whitespace), 105..106),
                (Ok(Float), 106..115),
                (Ok(Whitespace), 115..116),
                (Ok(Float), 116..125),
                (Ok(Whitespace), 125..126),
                (Ok(Float), 126..135),
                (Ok(Whitespace), 135..136),
                (Ok(Float), 136..145),
                (Ok(Whitespace), 145..146),
                (Ok(Float), 146..155),
                (Ok(Whitespace), 155..156),
                (Ok(Float), 156..165),
                (Ok(Whitespace), 165..166),
                (Ok(Float), 166..175),
                (Ok(Whitespace), 175..176),
                (Ok(Float), 176..185),
                (Ok(Whitespace), 185..186),
                (Ok(Float), 186..196),
                (Ok(Whitespace), 196..197),
                (Ok(Float), 197..207),
                (Ok(Whitespace), 207..208),
                (Ok(Float), 208..218),
                (Ok(Whitespace), 218..219),
                (Ok(Float), 219..229),
                (Ok(Whitespace), 229..230),
                (Ok(Float), 230..241),
                (Ok(Whitespace), 241..242),
                (Ok(Float), 242..253),
                (Ok(Whitespace), 253..254),
                (Ok(Float), 254..266),
                (Ok(Whitespace), 266..267),
                (Ok(Float), 267..279),
                (Ok(Whitespace), 279..280),
                (Ok(Float), 280..292),
                (Ok(Whitespace), 292..293),
                (Ok(Float), 293..305),
            ],
        );
    }

    #[test]
    fn integer() {
        use Token::*;
        let lexer = Lexer::<Token>::new(
            r#"
0
123456789
01234567
0000
0777
0x0
0X0
0x123456789ABCDEF"#,
        );
        let tokens: Vec<_> = lexer.map(map).collect();
        assert_eq!(
            tokens,
            &[
                (Ok(Whitespace), 0..1),
                (Ok(Integer), 1..2),
                (Ok(Whitespace), 2..3),
                (Ok(Integer), 3..12),
                (Ok(Whitespace), 12..13),
                (Ok(Integer), 13..21),
                (Ok(Whitespace), 21..22),
                (Ok(Integer), 22..26),
                (Ok(Whitespace), 26..27),
                (Ok(Integer), 27..31),
                (Ok(Whitespace), 31..32),
                (Ok(Integer), 32..35),
                (Ok(Whitespace), 35..36),
                (Ok(Integer), 36..39),
                (Ok(Whitespace), 39..40),
                (Ok(Integer), 40..57),
            ],
        );
    }

    #[test]
    fn ident() {
        use Token::*;

        let lexer = Lexer::<Token>::new(
            r#"
foo
Foo123
F_B
f_b
foo_Bar123
foo0123_bar0123_baz0123
foo123_BAR"#,
        );
        let tokens: Vec<_> = lexer.map(map).collect();
        assert_eq!(
            tokens,
            &[
                (Ok(Whitespace), 0..1),
                (Ok(Ident), 1..4),
                (Ok(Whitespace), 4..5),
                (Ok(Ident), 5..11),
                (Ok(Whitespace), 11..12),
                (Ok(Ident), 12..15),
                (Ok(Whitespace), 15..16),
                (Ok(Ident), 16..19),
                (Ok(Whitespace), 19..20),
                (Ok(Ident), 20..30),
                (Ok(Whitespace), 30..31),
                (Ok(Ident), 31..54),
                (Ok(Whitespace), 54..55),
                (Ok(Ident), 55..65),
            ],
        );
    }

    #[test]
    fn single_quote_string() {
        let mut lexer = Lexer::<Token>::new(r#"'hello \'钺礤А堙铒荥鲠蟒Б）狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉友郁蜷铉郁狎舂爱暴┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉藻舂碑珐┅狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉朋汜疱┈樊供┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉徐徙彖镬溴蛴翎螋┈巩北┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉射孱舂北钡┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈钡倍┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉徐徙彖镬溴蛴翎螋┈倍备┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉友郁蜷铉郁狎舂备惫┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉藻舂惫舶┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉蓬洎舶脖┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈脖膊┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉朋汜疱┈膊泊┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉藻舂泊嘲┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉朋汜疱┈嘲巢┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉藻舂巢掣┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉蚤熹濠掣彻┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉娘祆狎娱珙┈彻窗┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉藻舂窗幢┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄓ延趄轭缭镫孱汉蓬洎幢床┅┗戾眭戾弪戾弪盹蝠韬杭燥脲罹ī狍箦螋咤瘛戾弪铄舁┊磲皎磲皓物铄┗［翦篝骖滹踱戾唏躏翦唧趄轭绋戾眭戾弪体弪汉荚镫孱竞侯鬻颍㈣屐祜堍钺礤、堍铒荥鲠蟒）狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉难郁蜷铉郁狎舂爱暴┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂碑珐┅狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号筱狃濠樊供┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈盒灬沐栾熹弪郁狎舂巩北┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉射孱舂北钡┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈钡倍┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈盒灬沐栾熹弪郁狎舂倍备┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉难郁蜷铉郁狎舂备惫┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂惫舶┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号钿┈舶脖┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈脖膊┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号筱狃濠膊泊┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂泊嘲┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号筱狃濠嘲巢┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂巢掣┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸殪溴┈掣彻┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈耗镬灬蛴殓瞟彻窗┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂窗幢┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号钿┈幢床┅┗戾眭戾弪戾弪盹蝠韬杭燥脲罹ī狍箦螋咤瘛戾弪铄舁┊磲皎磲皓物铄┗［翦篝骖桢蝈滹悒戾眭戾弪体弪汉荚镫孱竞侯鬻颍⒓技痱轭翩礤篌徵妪痱轭翩鲠螨痱轭翩Ⅳ栝箬秕熹铒沆矬揪劲痱轭翩④弩汜疱潺芫揪篝殪轭桢蝈滹泾揪劲，┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉儒蝈滹忝镯磲钿郁狎舂爱畅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉藻舂钞钡┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉徐徙彖镬溴蛴翎螋┈钡狈┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉射孱舂狈泊┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈泊驳┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉藻舂驳刀┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉徐徙彖镬溴蛴翎螋┈刀蹈┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉难郁蜷铉郁狎舂蹈倒┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂倒复┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号钿┈复傅┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈傅付┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉藻舂付垢┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉朋汜疱┈垢卑癌┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉藻舂卑爱北穿┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉朋汜疱┈北串北订┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉蓬洎北懂北珐┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉蓬洎北樊北俯┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉藻舂北府背俯┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉蚤熹濠背府背供┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉藻舂背巩贝癌┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉蓬洎贝爱贝暴┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉蓬洎贝碑贝博┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄈ弪邃镢蔑眄犷湓镫孱汉蓬洎贝伯贝畅┗戾眭戾弪戾弪盹蝠韬杭燥脲罹ī狍箦螋咤瘛戾弪铄舁┊磲皎磲皓物铄┗［翦篝骖怛徙暹泔眄犷洙戾眭戾弪体弪汉荚镫孱竞侯鬻颍泔眄犷痱轭翩礤篌徵妪痱轭翩鲠螨痱轭翩Ⅳ栝箬秕熹铒沆矬痱轭翩④弩汜疱滠痱轭翩④犰箫弩汜疱滠痱轭翩Ⅲ糸祆轭泔眄犷浃，┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉蔑眄犷渌妁黠蜾┈爱珐┈┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉阻轸弩疳沐┈樊俯┈┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉橡孱买徙濠府供┈┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂巩脖┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈盒灬沐栾熹弪郁狎舂脖渤┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉射孱舂渤嘲┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈嘲潮┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂潮创┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈盒灬沐栾熹弪郁狎舂创炊┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉射孱舂炊垂┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈垂蛋┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂蛋恫┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈盒灬沐栾熹弪郁狎舂恫洞┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉难郁蜷铉郁狎舂洞兜┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈涸屮舂兜父┅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想难郁蜷铉燥脲詈号钿┈父腹┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想ㄔ镫孱汉渺矬迓蜥沐┈腹拱┅┗戾眭戾弪戾弪盹蝠瑷┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂拱卑博┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈号筱狃濠卑伯卑穿┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂卑串北博┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈号筱狃濠北伯北穿┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂北串辈珐┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈号筱狃濠辈樊辈供┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂辈巩贝博┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈号筱狃濠贝伯贝穿┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂贝串狈畅┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈耗镬灬蛴殓瞟狈钞狈穿┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸殪溴┈狈串狈旦┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈涸屮舂狈诞狈珐┗狍箦螋咤瘛戾弪铄舁┊磲皎磲皓语礤è想买徙迕镯磲钿燥脲詈号钿┈狈樊狈俯┗戾眭戾弪戾弪盹蝠韬杭燥脲罹ī狍箦螋咤瘛戾弪铄舁┊磲皎磲皓物铄┗［翦篝骖脲黠蜾蟥躞燥脲詈邯戾戾弪体弪汉荚镫孱竞侯鬻颍硫蜥嘛镬遽崎戾旗镝深歪物铄镶赍泗嗅轵郁蜷铉犰獒狍汜祆泔眄犷屐箦驷祗殒轭轫痫螋轭瘐礤翎铛祆镡赍泗秕麴豸疳蜥礤翦蜻礤翎蝓铘轫筱狒翦篝蝓泗翎箅翳孱趄蹂鲥蝮轱黠螂骒秣，┗戾麸脲铙皱慵呔戾弪磲皎磲皓泔祆邈舁┗狍箦螋咤瘛麸脲铙ㄏ毹阻轸弩疳沐┈爱暴ㄏ毹硫蜥赠疱隋黠蜾┈碑订ㄏ毹阻轸弩疳沐┈懂珐ㄏ毹嘛镬遽钤疱隋黠蜾┈樊贝┈ㄏ毹阻轸弩疳沐┈贝钡┈ㄏ毹崎戾赠疱隋黠蜾┈钡惫┈ㄏ毹阻轸弩疳沐┈惫舶┈ㄏ毹旗镝粼疱隋黠蜾┈舶驳┈ㄏ毹阻轸弩疳沐┈驳捕┈ㄏ毹深粼疱隋黠蜾┈捕补┈ㄏ毹阻轸弩疳沐┈补嘲┈ㄏ毹歪鹪疱隋黠蜾┈嘲吵┈ㄏ毹阻轸弩疳沐┈吵炒┈ㄏ毹物铄赠疱隋黠蜾┈炒掣┈ㄏ毹阻轸弩疳沐┈掣彻┈ㄏ毹镶赍泗赠疱隋黠蜾┈彻吹┈ㄏ毹阻轸弩疳沐┈吹炊┈ㄏ毹嗅轵赠疱隋黠蜾┈炊蛋┈ㄏ毹阻轸弩疳沐┈蛋当┈ㄏ毹郁蜷铉赠疱隋黠蜾┈当捣┈ㄏ毹阻轸弩疳沐┈捣蹈┈ㄏ毹领獒笏妁黠蜾┈蹈冻┈ㄏ毹阻轸弩疳沐┈冻洞┈ㄏ毹馏隋黠蜾┈洞抖┈ㄏ毹阻轸弩疳沐┈抖斗┈ㄏ毹冕祆隋黠蜾┈斗繁┈ㄏ毹阻轸弩疳沐┈繁凡┈ㄏ毹蔑眄犷渌妁黠蜾┈凡饭┈ㄏ毹阻轸弩疳沐┈饭赴┈ㄏ毹澎箦隋黠蜾┈赴复┈ㄏ毹阻轸弩疳沐┈复傅┈ㄏ毹漆祗逅妁黠蜾┈傅拱┈ㄏ毹阻轸弩疳沐┈拱贡┈ㄏ毹涉隋黠蜾┈贡钩┈ㄏ毹阻轸弩疳沐┈钩勾┈ㄏ毹深隋黠蜾┈勾苟┈ㄏ毹阻轸弩疳沐┈苟狗┈ㄏ毹身痫螋隋黠蜾┈狗卑畅ㄏ毹阻轸弩疳沐┈卑钞卑穿ㄏ毹深瘐羲妁黠蜾┈卑串卑供ㄏ毹阻轸弩疳沐┈卑巩北癌ㄏ毹湾翎隋黠蜾┈北爱北穿ㄏ毹阻轸弩疳沐┈北串北旦ㄏ毹熙祆隋黠蜾┈北诞北供ㄏ毹阻轸弩疳沐┈北巩辈癌ㄏ毹镶赍泗隋黠蜾┈辈爱辈订ㄏ毹阻轸弩疳沐┈辈懂辈珐ㄏ毹硝麴豸隋黠蜾┈辈樊背畅ㄏ毹阻轸弩疳沐┈背钞背穿ㄏ毹嗅蜥礤翦蛲弭崴妁黠蜾┈背串贝俯ㄏ毹阻轸弩疳沐┈贝府贝供ㄏ毹阴铘轫逅妁黠蜾┈贝巩钡订ㄏ毹阻轸弩疳沐┈钡懂钡珐ㄏ毹鱼狒翦蛩妁黠蜾┈钡樊倍穿ㄏ毹阻轸弩疳沐┈倍串倍旦ㄏ毹郁蝓泗隋黠蜾┈倍诞狈暴ㄏ毹阻轸弩疳沐┈狈碑狈博ㄏ毹葬箅隋黠蜾┈狈伯狈订ㄏ毹阻轸弩疳沐┈狈懂狈珐ㄏ毹澡孱隋黠蜾┈狈樊备暴ㄏ毹阻轸弩疳沐┈备碑备博ㄏ毹则蹂隋黠蜾┈备伯备订ㄏ毹阻轸弩疳沐┈备懂备珐ㄏ毹皱蝮轱钏妁黠蜾┈备樊惫穿ㄏ毹阻轸弩疳沐┈惫串惫旦ㄏ毹罪螂骒秣隋黠蜾┈惫诞舶畅莠┗［翦篝骖蝈箦蝣邃唠妁黠蜾蟥躞燥脲詈邯戾戾弪体弪汉荚镫孱竞侯鬻颍拈蝈泗矧栝铘蝈聃轵屙孱趔，┗戾麸脲铙皱慵呔戾弪磲皎磲皓泔祆邈舁┗狍箦螋咤瘛麸脲铙ㄏ毹阻轸弩疳沐┈爱暴ㄏ毹义箦蝣邃拈蝈泗矧赠疱隋黠蜾┈碑卑┈ㄏ毹阻轸弩疳沐┈卑北┈ㄏ毹义箦蝣邃乳铘笏妁黠蜾┈北倍┈ㄏ毹阻轸弩疳沐┈倍狈┈ㄏ毹义箦蝣邃义聃轵屙孱趔隋黠蜾┈狈补┈莠┗［翦篝骖簌礅镬蟥躞燥脲詈邯戾戾弪体弪汉荚镫孱竞侯鬻颍Ⅺ圯胶ī俊Ζソ健郊骄郊井）戾麸脲铙皱慵呔戾弪磲皎磲皓泔祆邈舁┗狍箦螋咤瘛麸脲铙ㄏ毹橡孱买徙濠爱暴ㄏ毹渺矬迓蜥沐┈碑博ㄏ毹橡孱买徙脲舂伯畅ㄏ毹渺矬迓蜥汶弭┈钞穿ㄏ毹馏箝珙礤铘┈串旦ㄏ毹蔑祜瞟诞订ㄏ毹蔑眄岍懂珐ㄏ毹橡孱嗅蝈瞟樊俯ㄏ毹渺矬逍狎孱┈府供ㄏ毹氧弩糸镱歪螂┈巩卑┈ㄏ毹砒沆犴狒轱瞟卑北┈ㄏ毹徐躞┈北辈┈ㄏ毹烷铛螬辈背┈ㄏ毹田玳汜煜颟背钡┈ㄏ毹田玳汜炝钿┈钡狈┈ㄏ毹馏翦蜷箅┈狈备┈ㄏ毹屿狍瑭备惫┈ㄏ毹绣蜚孱舂惫舶┈ㄏ毹篷踽飑舶膊┈ㄏ毹物襞聃犰┈膊泊┈ㄏ毹体篌篷踽飑泊捕┈ㄏ毹球遽翦蚺聃犰┈捕哺┈ㄏ毹体篌┈哺补┈ㄏ毹球遽翦颟补嘲┈ㄏ毹娘舂嘲潮┈莠┗